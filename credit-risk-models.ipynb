{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":666,"sourceType":"datasetVersion","datasetId":306}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/credit-risk-models?scriptVersionId=193634345\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T17:43:54.118401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the required libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:07.666848Z","iopub.execute_input":"2024-08-21T17:49:07.667612Z","iopub.status.idle":"2024-08-21T17:49:08.652232Z","shell.execute_reply.started":"2024-08-21T17:49:07.667564Z","shell.execute_reply":"2024-08-21T17:49:08.651355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the data and summary statistics\n\ndf = pd.read_csv ('/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv')\ndf.describe().transpose ().round (2)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:11.154897Z","iopub.execute_input":"2024-08-21T17:49:11.155758Z","iopub.status.idle":"2024-08-21T17:49:11.415544Z","shell.execute_reply.started":"2024-08-21T17:49:11.155719Z","shell.execute_reply":"2024-08-21T17:49:11.414384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COLS_TO_PLOT = [\"AGE\", \"LIMIT_BAL\", \"PAY_6\"]\npair_plot = sns.pairplot(df[COLS_TO_PLOT], kind=\"reg\", diag_kind=\"kde\", height=4, \n                         plot_kws={\"line_kws\":{\"color\":\"red\"}})\npair_plot.fig.suptitle(\"Pairplot of selected variables\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:14.128399Z","iopub.execute_input":"2024-08-21T17:49:14.129146Z","iopub.status.idle":"2024-08-21T17:49:27.778902Z","shell.execute_reply.started":"2024-08-21T17:49:14.12911Z","shell.execute_reply":"2024-08-21T17:49:27.777653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pair_plot = sns.pairplot(data=df, x_vars=COLS_TO_PLOT, \n                         y_vars=COLS_TO_PLOT, hue=\"SEX\",\n                         height=4)\npair_plot.fig.suptitle(\"Pairplot of selected variables\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.jointplot(data=df, x = \"AGE\", y= \"LIMIT_BAL\", hue=\"SEX\", height=10)\nax.fig.suptitle(\"Age vs. limit balance\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Function for plotting the correaltion heatmap**","metadata":{}},{"cell_type":"code","source":"def plot_correlation_matrix(corr_mat):\n    sns.set(style=\"white\")\n    mask = np.zeros_like(corr_mat, dtype=bool)\n    mask[np.triu_indices_from(mask)] = True\n    fig, ax = plt.subplots()\n    cmap = sns.diverging_palette(240, 10, n=9, as_cmap=True)\n    sns.heatmap(corr_mat, mask=mask, cmap=cmap, \n                vmax=.3, center=0, square=True,\n                linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n    ax.set_title(\"Correlation Matrix\", fontsize=16)\n    sns.set(style=\"darkgrid\")\n    \ncorr_mat = df.select_dtypes(include=\"number\").corr()\nplot_correlation_matrix(corr_mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.boxplot(data=df, y=\"AGE\", x=\"MARRIAGE\", hue=\"SEX\")\nax.set_title(\"Distribution of age\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.violinplot(x=\"EDUCATION\", y=\"LIMIT_BAL\", hue=\"SEX\", split=True, data=df)\nax.set_title(\"Distribution of limit balance per education level\", fontsize=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = df.groupby(\"EDUCATION\")[\"default.payment.next.month\"].value_counts(normalize=True).unstack() \\\n.plot(kind=\"barh\", stacked=\"True\")\nax.set_title(\"Percentage of default per education level\", fontsize=16)\nax.legend(title=\"Default\", bbox_to_anchor=(1,1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training the model**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.copy()\ny = X.pop(\"default.payment.next.month\")\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = False)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)\n\nprint(\"Target distribution - train\")\nprint(y_train.value_counts(normalize = True).values)\nprint(\"Target distribution - test\")\nprint(y_test.value_counts(normalize = True).values)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:33.880597Z","iopub.execute_input":"2024-08-21T17:49:33.881549Z","iopub.status.idle":"2024-08-21T17:49:34.116395Z","shell.execute_reply.started":"2024-08-21T17:49:33.881502Z","shell.execute_reply":"2024-08-21T17:49:34.115135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the size of the validation and test sets\nVALID_SIZE = 0.1\nTEST_SIZE = 0.2\n\n# create the initial split - training and temp\nX_train, X_temp, y_train, y_temp = train_test_split(X, y,\n                                                    test_size=(VALID_SIZE + TEST_SIZE),\n                                                    stratify=y,random_state=42)\n\n# calculate the new test size\nnew_test_size = np.around(TEST_SIZE / (VALID_SIZE + TEST_SIZE), 2)\n\n# create the valid and test sets\nX_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp,\n                                                    test_size=new_test_size,\n                                                    stratify=y_temp,\n                                                    random_state=42)\n\nprint(\"Percentage of data in each set ----\")\nprint(f\"Train: {100 * len(X_train) / len(X):.2f}%\")\nprint(f\"Valid: {100 * len(X_valid) / len(X):.2f}%\")\nprint(f\"Test: {100 * len(X_test) / len(X):.2f}%\")\nprint(\"\")\nprint(\"Class distribution in each set ----\")\nprint(f\"Train: {y_train.value_counts(normalize=True).values}\")\nprint(f\"Valid: {y_valid.value_counts(normalize=True).values}\")\nprint(f\"Test: {y_test.value_counts(normalize=True).values}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:36.285346Z","iopub.execute_input":"2024-08-21T17:49:36.286375Z","iopub.status.idle":"2024-08-21T17:49:36.328869Z","shell.execute_reply.started":"2024-08-21T17:49:36.28633Z","shell.execute_reply":"2024-08-21T17:49:36.327648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dealing with missing values\nimport missingno as msno\nfrom sklearn.impute import SimpleImputer\n\nX.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:39.105196Z","iopub.execute_input":"2024-08-21T17:49:39.10559Z","iopub.status.idle":"2024-08-21T17:49:39.281125Z","shell.execute_reply.started":"2024-08-21T17:49:39.105558Z","shell.execute_reply":"2024-08-21T17:49:39.280068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the missing values (we don't have this)\nmsno.matrix(X)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:41.684779Z","iopub.execute_input":"2024-08-21T17:49:41.685196Z","iopub.status.idle":"2024-08-21T17:49:42.771117Z","shell.execute_reply.started":"2024-08-21T17:49:41.685164Z","shell.execute_reply":"2024-08-21T17:49:42.769766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decision tree classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn import metrics\n\ntree_classifier = DecisionTreeClassifier(random_state=42)\ntree_classifier.fit(X_train, y_train)\ny_pred = tree_classifier.predict(X_test)\n\nplot_tree(tree_classifier, max_depth=3, fontsize=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:46.611659Z","iopub.execute_input":"2024-08-21T17:49:46.612055Z","iopub.status.idle":"2024-08-21T17:49:48.558795Z","shell.execute_reply.started":"2024-08-21T17:49:46.612024Z","shell.execute_reply":"2024-08-21T17:49:48.557761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_tree(tree_classifier,max_depth=2,\n          feature_names=X_train.columns,\n          class_names=[\"No default\", \"Default\"],\n          rounded=True, filled=True, fontsize=10\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:49:57.294515Z","iopub.execute_input":"2024-08-21T17:49:57.294995Z","iopub.status.idle":"2024-08-21T17:49:57.975423Z","shell.execute_reply.started":"2024-08-21T17:49:57.294956Z","shell.execute_reply":"2024-08-21T17:49:57.974205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for performance evaluation report\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndef performance_evaluation_report(model, X_test, y_test, show_plot=False, labels=None, show_pr_curve=False):\n    \"\"\"\n    Function for creating a performance report of a classification model.\n    \n    Parameters\n    ----------\n    model : scikit-learn estimator\n        A fitted estimator for classification problems.\n    X_test : pd.DataFrame\n        DataFrame with features matching y_test\n    y_test : array/pd.Series\n        Target of a classification problem.\n    show_plot : bool\n        Flag whether to show the plot\n    labels : list\n        List with the class names.\n    show_pr_curve : bool\n        Flag whether to also show the PR-curve. For this to take effect, \n        show_plot must be True.\n        \n    Return\n    ------\n    stats : pd.Series\n        A series with the most important evaluation metrics\n    \"\"\"\n\n    y_pred = model.predict(X_test)\n    y_pred_prob = model.predict_proba(X_test)[:, 1]\n\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n\n    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_prob)\n    roc_auc = metrics.auc(fpr, tpr)\n\n    precision, recall, _ = metrics.precision_recall_curve(\n        y_test, y_pred_prob)\n    pr_auc = metrics.auc(recall, precision)\n\n    if show_plot:\n\n        if labels is None:\n            labels = [\"Negative\", \"Positive\"]\n\n        N_SUBPLOTS = 3 if show_pr_curve else 2\n        PLOT_WIDTH = 20 if show_pr_curve else 12\n        PLOT_HEIGHT = 5 if show_pr_curve else 6\n\n        fig, ax = plt.subplots(\n            1, N_SUBPLOTS, figsize=(PLOT_WIDTH, PLOT_HEIGHT))\n        fig.suptitle(\"Performance Evaluation\", fontsize=16)\n\n        # plot 1: confusion matrix ----\n        \n        # preparing more descriptive labels for the confusion matrix\n        cm_counts = [f\"{val:0.0f}\" for val in cm.flatten()]\n        cm_percentages = [f\"{val:.2%}\" for val in cm.flatten()/np.sum(cm)]\n        cm_labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(cm_counts,cm_percentages)]\n        cm_labels = np.asarray(cm_labels).reshape(2,2)\n\n        sns.heatmap(cm, annot=cm_labels, fmt=\"\", linewidths=.5, cmap=\"Greens\", \n                    square=True, cbar=False, ax=ax[0],\n                    annot_kws={\"ha\": \"center\", \"va\": \"center\"})\n        ax[0].set(xlabel=\"Predicted label\",\n                  ylabel=\"Actual label\", title=\"Confusion Matrix\")\n        ax[0].xaxis.set_ticklabels(labels)\n        ax[0].yaxis.set_ticklabels(labels)\n\n        # plot 2: ROC curve ----\n        \n        metrics.RocCurveDisplay.from_estimator(model, X_test, y_test, ax=ax[1], name=\"\")\n        ax[1].set_title(\"ROC Curve\")\n        ax[1].plot(fp/(fp+tn), tp/(tp+fn), \"ro\",\n                   markersize=8, label=\"Decision Point\")\n        ax[1].plot([0, 1], [0, 1], \"r--\")\n        \n        # alternatively:\n        # ax[1].plot(fpr, tpr, \"b-\", label=f\"ROC-AUC = {roc_auc:.2f}\")\n        # ax[1].set(xlabel=\"False Positive Rate\",\n        #           ylabel=\"True Positive Rate\", title=\"ROC Curve\")\n        # ax[1].plot(fp/(fp+tn), tp/(tp+fn), \"ro\",\n        #            markersize=8, label=\"Decision Point\")\n        # ax[1].plot([0, 1], [0, 1], \"r--\")\n        # ax[1].legend(loc=\"lower right\")\n        \n        # plot 3: Precision-Recall curve ----\n\n        if show_pr_curve:\n\n            metrics.PrecisionRecallDisplay.from_estimator(model, X_test, y_test, ax=ax[2], name=\"\")\n            ax[2].set_title(\"Precision-Recall Curve\")\n            \n            # alternatively:\n            # ax[2].plot(recall, precision, label=f\"PR-AUC = {pr_auc:.2f}\")\n            # ax[2].set(xlabel=\"Recall\", ylabel=\"Precision\",\n            #           title=\"Precision-Recall Curve\")\n            # ax[2].legend()\n\n    stats = {\n        \"accuracy\": metrics.accuracy_score(y_test, y_pred),\n        \"precision\": metrics.precision_score(y_test, y_pred),\n        \"recall\": metrics.recall_score(y_test, y_pred),\n        \"specificity\": (tn / (tn + fp)),\n        \"f1_score\": metrics.f1_score(y_test, y_pred),\n        \"cohens_kappa\": metrics.cohen_kappa_score(y_test, y_pred),\n        \"matthews_corr_coeff\": metrics.matthews_corrcoef(y_test, y_pred),\n        \"roc_auc\": roc_auc,\n        \"pr_auc\": pr_auc,\n        \"average_precision\": metrics.average_precision_score(y_test, y_pred_prob)\n    }\n\n    return stats","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:00.739288Z","iopub.execute_input":"2024-08-21T17:50:00.740057Z","iopub.status.idle":"2024-08-21T17:50:00.757874Z","shell.execute_reply.started":"2024-08-21T17:50:00.740013Z","shell.execute_reply":"2024-08-21T17:50:00.756686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABELS = [\"No Default\", \"Default\"]\ntree_perf = performance_evaluation_report(tree_classifier,\n                                          X_test,y_test, labels=LABELS,\n                                          show_plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:14.422189Z","iopub.execute_input":"2024-08-21T17:50:14.422627Z","iopub.status.idle":"2024-08-21T17:50:14.88764Z","shell.execute_reply.started":"2024-08-21T17:50:14.422592Z","shell.execute_reply":"2024-08-21T17:50:14.886515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation metrics of classification**","metadata":{}},{"cell_type":"code","source":"y_pred_prob = tree_classifier.predict_proba(X_test)[:, 1]\nprecision, recall, _ = metrics.precision_recall_curve(y_test, y_pred_prob)\n\nax = plt.subplot()\nax.plot(recall, precision,\n        label=f\"PR-AUC = {metrics.auc(recall, precision):.2f}\")\nax.set(title=\"Precision-Recall Curve\", xlabel=\"Recall\", ylabel=\"Precision\")\nax.legend()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:20.943119Z","iopub.execute_input":"2024-08-21T17:50:20.943543Z","iopub.status.idle":"2024-08-21T17:50:21.230471Z","shell.execute_reply.started":"2024-08-21T17:50:20.943507Z","shell.execute_reply":"2024-08-21T17:50:21.22942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = metrics.PrecisionRecallDisplay.from_estimator(tree_classifier, X_test, y_test)\nax.ax_.set_title(\"Precision-Recall Curve\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:23.559618Z","iopub.execute_input":"2024-08-21T17:50:23.560015Z","iopub.status.idle":"2024-08-21T17:50:23.843873Z","shell.execute_reply.started":"2024-08-21T17:50:23.559983Z","shell.execute_reply":"2024-08-21T17:50:23.842813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating pipeline**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\n\n\ndf = pd.read_csv(\"/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\", na_values=\"\")\nX = df.copy()\ny = X.pop(\"default.payment.next.month\")\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.2,\n                                                    stratify=y,\n                                                    random_state=42\n)\n\nnum_features = X_train.columns.to_list()\nnum_pipeline = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:26.517457Z","iopub.execute_input":"2024-08-21T17:50:26.517867Z","iopub.status.idle":"2024-08-21T17:50:26.639571Z","shell.execute_reply.started":"2024-08-21T17:50:26.517826Z","shell.execute_reply":"2024-08-21T17:50:26.638494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(transformers=[(\"numerical\", num_pipeline, num_features)],\n                                 remainder=\"drop\")\n\ndec_tree = DecisionTreeClassifier(random_state=42)\ntree_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),\n                                (\"classifier\", dec_tree)\n])\n\ntree_pipeline.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:33.233871Z","iopub.execute_input":"2024-08-21T17:50:33.234301Z","iopub.status.idle":"2024-08-21T17:50:34.106533Z","shell.execute_reply.started":"2024-08-21T17:50:33.234268Z","shell.execute_reply":"2024-08-21T17:50:34.10526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABELS = [\"No Default\", \"Default\"]\ntree_perf = performance_evaluation_report(tree_pipeline, X_test,\n                                          y_test, labels=LABELS,\n                                          show_plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:36.872652Z","iopub.execute_input":"2024-08-21T17:50:36.873043Z","iopub.status.idle":"2024-08-21T17:50:37.394814Z","shell.execute_reply.started":"2024-08-21T17:50:36.873013Z","shell.execute_reply":"2024-08-21T17:50:37.393699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport numpy as np\n\nclass OutlierRemover(BaseEstimator, TransformerMixin):\n    def __init__(self, n_std=3):\n        self.n_std = n_std\n    def fit(self, X, y = None):\n        if np.isnan(X).any(axis=None):\n            raise ValueError(\"\"\"Missing values in the array! Please remove them.\"\"\")\n        mean_vec = np.mean(X, axis=0)\n        std_vec = np.std(X, axis=0)\n        self.upper_band_ = pd.Series(mean_vec + self.n_std * std_vec)\n        self.upper_band_ = (\n        self.upper_band_.to_frame().transpose())\n        self.lower_band_ = pd.Series(\n        mean_vec - self.n_std * std_vec)\n        self.lower_band_ = (\n        self.lower_band_.to_frame().transpose())\n        self.n_features_ = len(self.upper_band_.columns)\n        return self\n\n    def transform(self, X, y = None):\n        X_copy = pd.DataFrame(X.copy())\n        upper_band = pd.concat([self.upper_band_] * len(X_copy),\n                               ignore_index=True)\n        lower_band = pd.concat([self.lower_band_] * len(X_copy),\n                               ignore_index=True)\n        X_copy[X_copy >= upper_band] = upper_band\n        X_copy[X_copy <= lower_band] = lower_band\n        return X_copy.values","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:40.64787Z","iopub.execute_input":"2024-08-21T17:50:40.648256Z","iopub.status.idle":"2024-08-21T17:50:40.659148Z","shell.execute_reply.started":"2024-08-21T17:50:40.648227Z","shell.execute_reply":"2024-08-21T17:50:40.657732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pipeline = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),(\"outliers\", OutlierRemover())])\npreprocessor = ColumnTransformer(transformers=[(\"numerical\", num_pipeline, num_features)],remainder=\"drop\")\ndec_tree = DecisionTreeClassifier(random_state=42)\ntree_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", dec_tree)])\ntree_pipeline.fit(X_train, y_train)\n\ntree_perf = performance_evaluation_report(tree_pipeline, X_test,\n                                          y_test, labels=LABELS,\n                                          show_plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:43.22543Z","iopub.execute_input":"2024-08-21T17:50:43.226407Z","iopub.status.idle":"2024-08-21T17:50:45.458965Z","shell.execute_reply.started":"2024-08-21T17:50:43.226372Z","shell.execute_reply":"2024-08-21T17:50:45.457737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_pipeline.named_steps\ntree_pipeline.named_steps[\"classifier\"]\n(tree_pipeline.named_steps[\"preprocessor\"].named_transformers_[\"numerical\"][\"outliers\"].upper_band_)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:48.933837Z","iopub.execute_input":"2024-08-21T17:50:48.934245Z","iopub.status.idle":"2024-08-21T17:50:48.958537Z","shell.execute_reply.started":"2024-08-21T17:50:48.934211Z","shell.execute_reply":"2024-08-21T17:50:48.957154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import (GridSearchCV, cross_val_score,\n                                     RandomizedSearchCV, cross_validate,\n                                     StratifiedKFold)\nfrom sklearn import metrics\nk_fold = StratifiedKFold(5, shuffle=True, random_state=42)\ncross_val_score(tree_pipeline, X_train, y_train, cv=k_fold)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:50:54.240374Z","iopub.execute_input":"2024-08-21T17:50:54.240883Z","iopub.status.idle":"2024-08-21T17:50:59.74732Z","shell.execute_reply.started":"2024-08-21T17:50:54.240846Z","shell.execute_reply":"2024-08-21T17:50:59.746229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_scores = cross_validate(tree_pipeline, X_train, y_train, cv=k_fold,\n                           scoring=[\"accuracy\", \"precision\", \"recall\",\"roc_auc\"])\npd.DataFrame(cv_scores)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:51:01.798498Z","iopub.execute_input":"2024-08-21T17:51:01.799244Z","iopub.status.idle":"2024-08-21T17:51:07.808666Z","shell.execute_reply.started":"2024-08-21T17:51:01.799209Z","shell.execute_reply":"2024-08-21T17:51:07.807372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n    \"classifier__criterion\": [\"entropy\", \"gini\"],\n    \"classifier__max_depth\": range(3, 11),\n    \"classifier__min_samples_leaf\": range(2, 11),\n    \"preprocessor__numerical__outliers__n_std\": [3, 4]\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:51:10.438627Z","iopub.execute_input":"2024-08-21T17:51:10.439028Z","iopub.status.idle":"2024-08-21T17:51:10.444416Z","shell.execute_reply.started":"2024-08-21T17:51:10.438997Z","shell.execute_reply":"2024-08-21T17:51:10.443191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_gs = GridSearchCV(tree_pipeline, param_grid,scoring=\"recall\", \n                             cv=k_fold, n_jobs=-1, verbose=1)\nclassifier_gs.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:51:13.814745Z","iopub.execute_input":"2024-08-21T17:51:13.815138Z","iopub.status.idle":"2024-08-21T17:58:22.619038Z","shell.execute_reply.started":"2024-08-21T17:51:13.81511Z","shell.execute_reply":"2024-08-21T17:58:22.61789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABELS = [\"No Default\", \"Default\"]\ntree_gs_perf = performance_evaluation_report(\n    classifier_gs, X_test,\n    y_test, labels=LABELS,\n    show_plot=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T17:58:23.435911Z","iopub.execute_input":"2024-08-21T17:58:23.436639Z","iopub.status.idle":"2024-08-21T17:58:24.355029Z","shell.execute_reply.started":"2024-08-21T17:58:23.436602Z","shell.execute_reply":"2024-08-21T17:58:24.353895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_rs = RandomizedSearchCV(tree_pipeline, param_grid, scoring=\"recall\", \n                                   cv=k_fold, n_jobs=-1, verbose=1,\n                                   n_iter=100, random_state=42)\nclassifier_rs.fit(X_train, y_train)\nprint(f\"Best parameters: {classifier_rs.best_params_}\")\nprint(f\"Recall (Training set): {classifier_rs.best_score_:.4f}\")\nprint(f\"Recall (Test set): {metrics.recall_score(y_test, classifier_rs.predict(X_test)):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T18:00:27.938197Z","iopub.execute_input":"2024-08-21T18:00:27.938689Z","iopub.status.idle":"2024-08-21T18:02:54.842321Z","shell.execute_reply.started":"2024-08-21T18:00:27.938655Z","shell.execute_reply":"2024-08-21T18:02:54.841204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.experimental import enable_halving_search_cv\nfrom sklearn.model_selection import HalvingGridSearchCV\n\nclassifier_sh = HalvingGridSearchCV(tree_pipeline, param_grid,\n                                    scoring=\"recall\", cv=k_fold,\n                                    n_jobs=-1, verbose=1,\n                                    min_resources=\"exhaust\", factor=3)\nclassifier_sh.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T18:04:05.495525Z","iopub.execute_input":"2024-08-21T18:04:05.495937Z","iopub.status.idle":"2024-08-21T18:04:49.266953Z","shell.execute_reply.started":"2024-08-21T18:04:05.495907Z","shell.execute_reply":"2024-08-21T18:04:49.265704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nparam_grid = [\n    {\"classifier\": [RandomForestClassifier(random_state=42)],\n     \"classifier__n_estimators\": np.linspace(100, 500, 10, dtype=int),\n     \"classifier__max_depth\": range(3, 11),\n     \"preprocessor__numerical__outliers__n_std\": [3, 4]},\n    {\"classifier\": [DecisionTreeClassifier(random_state=42)],\n     \"classifier__criterion\": [\"entropy\", \"gini\"],\n     \"classifier__max_depth\": range(3, 11),\n     \"classifier__min_samples_leaf\": range(2, 11),\n     \"preprocessor__numerical__outliers__n_std\": [3, 4]}\n]\n\nclassifier_gs_2 = GridSearchCV(tree_pipeline, param_grid,\n                               scoring=\"recall\", cv=k_fold,\n                               n_jobs=-1, verbose=1)\nclassifier_gs_2.fit(X_train, y_train)\n\nprint(f\"Best parameters: {classifier_gs_2.best_params_}\")\nprint(f\"Recall (Training set): {classifier_gs_2.best_score_:.4f}\")\nprint(f\"Recall (Test set): {metrics.recall_score(y_test, classifier_gs_2.predict(X_test)):.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(classifier_gs_2.cv_results_).sort_values(\"rank_test_score\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**More advanced methods for training the model**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\nfrom xgboost.sklearn import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nrf = RandomForestClassifier(random_state=42)\nrf_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),\n                              (\"classifier\", rf)])\nrf_pipeline.fit(X_train, y_train)\n\nrf_perf = performance_evaluation_report(rf_pipeline, X_test,\n                                        y_test, labels=LABELS,\n                                        show_plot=True,\n                                        show_pr_curve=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbt = GradientBoostingClassifier(random_state=42)\ngbt_pipeline = Pipeline(\nsteps=[(\"preprocessor\", preprocessor), (\"classifier\", gbt)])\ngbt_pipeline.fit(X_train, y_train)\n\ngbt_perf = performance_evaluation_report(gbt_pipeline, X_test,\n                                         y_test, labels=LABELS,\n                                         show_plot=True,\n                                         show_pr_curve=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(random_state=42)\nxgb_pipeline = Pipeline(\nsteps=[(\"preprocessor\", preprocessor), (\"classifier\", xgb)])\nxgb_pipeline.fit(X_train, y_train)\n\nxgb_perf = performance_evaluation_report(xgb_pipeline, X_test,\n                                         y_test, labels=LABELS,\n                                         show_plot=True,\n                                         show_pr_curve=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=42)\nlgbm_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),(\"classifier\", lgbm)])\nlgbm_pipeline.fit(X_train, y_train)\n\nlgbm_pipeline.fit(X_train, y_train)\nlgbm_perf = performance_evaluation_report(lgbm_pipeline, X_test,\n                                          y_test, labels=LABELS,\n                                          show_plot=True,\n                                          show_pr_curve=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling with imbalanced data**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import RobustScaler\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.ensemble import BalancedRandomForestClassifier\n\nRANDOM_STATE = 42\ndf = pd.read_csv(\"/kaggle/input/fraud-detection/fraudTrain.csv\")\nX = df.copy().drop(columns=[\"trans_date_trans_time\"])\ny = X.pop(\"Class\")\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,\n    stratify=y,\n    random_state=RANDOM_STATE\n)\n\nrobust_scaler = RobustScaler()\nX_train = robust_scaler.fit_transform(X_train)\nX_test = robust_scaler.transform(X_test)\nrf = RandomForestClassifier(\nrandom_state=RANDOM_STATE, n_jobs=-1\n)\nrf.fit(X_train, y_train)\n\nrus = RandomUnderSampler(random_state=RANDOM_STATE)\nX_rus, y_rus = rus.fit_resample(X_train, y_train)\nrf.fit(X_rus, y_rus)\nrf_rus_perf = performance_evaluation_report(rf, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:04:22.239127Z","iopub.execute_input":"2024-08-22T18:04:22.242893Z","iopub.status.idle":"2024-08-22T18:04:38.322945Z","shell.execute_reply.started":"2024-08-22T18:04:22.242841Z","shell.execute_reply":"2024-08-22T18:04:38.321311Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Class'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/fraud-detection/fraudTrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrans_date_trans_time\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     14\u001b[0m     X, y,\n\u001b[1;32m     15\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     16\u001b[0m     stratify\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m     17\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m robust_scaler \u001b[38;5;241m=\u001b[39m RobustScaler()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5819\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   5778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5780\u001b[0m \u001b[38;5;124;03m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[1;32m   5781\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[38;5;124;03m    3  monkey        NaN\u001b[39;00m\n\u001b[1;32m   5818\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:947\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[0;32m--> 947\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'Class'"],"ename":"KeyError","evalue":"'Class'","output_type":"error"}]}]}